## Reinforcement Learning 
* [Non-Linear Reinforcement Learning in Large Action Spaces:
Structural Conditions and Sample-efficiency of Posterior Sampling](https://arxiv.org/pdf/2203.08248.pdf)
  * Alekh Agarwal, Tong Zhang, COLT 2022 
* [Offline Reinforcement Learning: Fundamental Barriers for Value Function Approximation](https://proceedings.mlr.press/v178/foster22a/foster22a.pdf)
  * Dylan J Foster, Akshay Krishnamurthy, David Simchi-Levi, Yunzong Xu, COLT 2022. 
* [Sample-Efficient Reinforcement Learning in the Presence of Exogenous Information](https://proceedings.mlr.press/v178/efroni22a/efroni22a.pdf)
  * Yonathan Efroni, Dylan J Foster, Dipendra Misra, Akshay Krishnamurthy, John Langford, COLT 2022. 
* [Online Markov Decision Processes with Aggregate Bandit Feedback]()
* [Instance-Dependent Complexity of Contextual Bandits and Reinforcement Learning: A Disagreement-Based Perspective]() 
* [Mirror Descent and the Information Ratio]()
* [Softmax Policy Gradient Methods Can Take Exponential Time to Converge]()
* [Corruption-robust exploration in episodic reinforcement learning]()
* [Improved Analysis of the Tsallis-INF Algorithm in Stochastically Constrained Adversarial Bandits and Stochastic Bandits with Adversarial Corruptions]()
* [Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive Multi-Step Bootstrap]()
* [Cautiously Optimistic Policy Optimization and Exploration with Linear Function Approximation]()
* [Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal Algorithm Escaping the Curse of Horizon]()
* [Nearly Minimax Optimal Reinforcement Learning for Linear Mixture Markov Decision Processes]()
* [Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes]()
* [Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal]()
* [Root-n-Regret for Learning in Markov Decision Processes with Function Approximation and Low Bellman Rank]()
* [Smooth Contextual Bandits: Bridging the Parametric and Non-differentiable Regret Regimes]()
* [Provably efficient reinforcement learning with linear function approximation]()
* [Exploration by Optimisation in Partial Monitoring]()
* [Efficient and robust algorithms for adversarial linear contextual bandits]()
* [Tsallis-INF for Decoupled Exploration and Exploitation in Multi-armed Bandits]()

## Robustness and Distribution Shifts 
* [Minimax Regret Optimization for Robust Machine Learning under Distribution Shift](https://arxiv.org/pdf/2202.05436.pdf)
  * Alekh Agarwal, Tong Zhang, COLT 2022   
* [On the power of adaptivity in statistical adversaries](https://proceedings.mlr.press/v178/blanc22a/blanc22a.pdf) 
  * Guy Blanc, Jane Lange, Ali Malik, Li-Yang Tan, COLT 2022 
* [A law of robustness for two-layers neural networks](https://arxiv.org/abs/2009.14444)
  * Sébastien Bubeck, Yuanzhi Li, Dheeraj Nagaraj, COLT 2021 
* [The Sample Complexity of Robust Covariance Testing]()
* [Adversarially Robust Learning with Unknown Perturbation Sets]()
* [Precise Tradeoffs in Adversarial Training for Linear Regression]()
* [Robust causal inference under covariate shift via worst-case subpopulation treatment effects]()
* [Certifying Some Distributional Robustness with Principled Adversarial Training]()

## Neural networks 
* [On the Approximation Power of Two-Layer Networks of Random ReLUs]()
* [The Connection Between Approximation, Depth Separation and Learnability in Neural Networks]()
* [A Local Convergence Theory for Mildly Over-Parameterized Two-Layer Neural Network]()
* [Benign Overfitting of Constant-Stepsize SGD for Linear Regression]()
* [Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process]()
* [A Corrective View of Neural Networks: Representation, Memorization and Learning]()
* [Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss]()
* [Learning Over-Parametrized Two-Layer Neural Networks beyond NTK]()
* [Kernel and Rich Regimes in Overparametrized Models]()
* [Learning a Single Neuron with Gradient Methods]()

## Multi-player bandits 
* [Towards Optimal Algorithms for Multi-Player Bandits without Collision Sensing Information](https://arxiv.org/pdf/2103.13059.pdf)
  * Wei Huang, Richard Combes, and Cindy Trinh, COLT 2022. 
* [Multiplayer Bandit Learning, from Competition to Cooperation](https://arxiv.org/abs/1908.01135)
  * Simina Brânzei, Yuval Peres, COLT 2021. 
* [Cooperative and Stochastic Multi-Player Multi-Armed Bandit: Optimal Regret With Neither Communication Nor Collisions](http://proceedings.mlr.press/v134/bubeck21b/bubeck21b.pdf) 
  * Sebastien Bubeck, Thomas Budzinski, Mark Sellke, COLT 2021
* [Selfish Robustness and Equilibria in Multi-Player Bandits]()
* [Coordination without communication: optimal regret in two players multi-armed bandits]()
* [Non-Stochastic Multi-Player Multi-Armed Bandits: Optimal Rate With Collision Information, Sublinear Without]()
